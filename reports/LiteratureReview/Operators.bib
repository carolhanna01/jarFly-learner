@article{LeGoues2012,
abstract = {Evolutionary computation is a promising technique for automating time-consuming and expensive software maintenance tasks, including bug repair. The success of this approach, however, depends at least partially on the choice of representation, fitness function, and operators. Previous work on evolutionary software repair has employed different approaches, but they have not yet been evaluated in depth. This paper investigates representation and operator choices for source-level evolutionary program repair in the GenProg framework [17], focusing on: (1) representation of individual variants, (2) crossover design, (3) mutation operators, and (4) search space definition. We evaluate empirically on a dataset comprising 8 C programs totaling over 5.1 million lines of code and containing 105 reproducible, human-confirmed defects. Our results provide concrete suggestions for operator and representation design choices for evolutionary program repair. When augmented to incorporate these suggestions, GenProg repairs 5 additional bugs (60 vs. 55 out of 105), with a decrease in repair time of 17{43% for the more dificult repair searches. {\textcopyright} 2012 ACM.}},
author = {{Le Goues}, Claire and Wemer, Westley and Forrest, Stephanie},
doi = {10.1145/2330163.2330296},
file = {:C\:/Users/carol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Le Goues, Wemer, Forrest - 2012 - Representations and operators for improving evolutionary software repair.pdf:pdf},
isbn = {9781450311779},
journal = {GECCO'12 - Proceedings of the 14th International Conference on Genetic and Evolutionary Computation},
keywords = {crossover,genetic programming,mutation,representation,search-based software engineering,software repair},
pages = {959--966},
title = {{Representations and operators for improving evolutionary software repair}},
year = {2012}
}
@article{Zhang2021,
abstract = {Adaptive parameter control and mutation operator selection are two important research avenues in differential evolution (DE). Existing works consider the two avenues independently. In this paper, we propose to unify the two modules and develop a unified parameterized mutation operator. With different settings of the parameters, different mutation operators can be retrieved. Further, the settings of the parameters closely relate to the control parameters of the DE. By determining the parameters we can achieve adaptive parameter control and mutation operator selection simultaneously. We propose to use a neural network to output the parameters and learn the network parameter by the natural evolution strategies algorithm under the consideration of modeling the evolution process as a Markov Decision Process. Experimental results on the CEC 2018 test suite show that the proposed method performs significantly better than traditional DEs with different operators and an advanced adaptive DE. We further analyze the time complexity and population diversity of the proposed method. The analysis shows that our method can achieve a balanced exploration and exploitation with a properly learned network.},
author = {Zhang, Haotian and Sun, Jianyong and Xu, Zongben},
doi = {10.1109/CEC45853.2021.9504990},
file = {:C\:/Users/carol/Downloads/Learning_to_Mutate_for_Differential_Evolution.pdf:pdf},
isbn = {9781728183923},
journal = {2021 IEEE Congress on Evolutionary Computation, CEC 2021 - Proceedings},
keywords = {Adaptive operator selection,Adaptive parameter control,Differential evolution,Markov descision process},
pages = {1--8},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Learning to Mutate for Differential Evolution}},
year = {2021}
}
@article{Soria-Alcaraz2014,
abstract = {Evolvability metrics gauge the potential for fitness of an individual rather than fitness itself. They measure the local characteristics of the fitness landscape surrounding a solution. In adaptive operator selection the goal is to dynamically select from a given pool the operator to apply next during the search process. An important component of these adaptive schemes is credit assignment, whereby operators are rewarded according to their observed performance. This article brings the notion of evolvability to adaptive operator selection, by proposing an autonomous search algorithm that rewards operators according to their potential for fitness rather than their immediate fitness improvement. The approach is tested within an evolutionary algorithm framework featuring several mutation operators on binary strings. Three benchmark problems of increasing dificulty, Onemax, Royal Staircase and Multiple Knapsack are considered. Experiments reveal that evolvability metrics significantly improve the performance of adaptive operator selection, when compared against standard fitness improvement metrics.The main contribution is to effectively use fitness landscape metrics to guide a self-configuring algorithm. {\textcopyright} 2014 ACM.},
author = {Soria-Alcaraz, Jorge A. and Ochoa, Gabriela and Carpio, Martin and Puga, Hector},
doi = {10.1145/2576768.2598220},
file = {:C\:/Users/carol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Soria-Alcaraz et al. - 2014 - Evolvability metrics in adaptive operator selection.pdf:pdf},
isbn = {9781450326629},
journal = {GECCO 2014 - Proceedings of the 2014 Genetic and Evolutionary Computation Conference},
keywords = {Adaptive operator selection,Combinatorial optimization,Evolutionary algorithms,Evolvability,Fitness landscapes,Hyper-heuristics,Self-* search,fitness landscapes,hyper-heuristics,self-* search},
pages = {1327--1334},
publisher = {Association for Computing Machinery},
title = {{Evolvability metrics in adaptive operator selection}},
url = {http://dx.doi.org/10.1145/2576768.2598220.},
year = {2014}
}
@article{Hong2000,
abstract = {The mutation operation is critical to the success of genetic algorithms since it diversifies the search directions and avoids convergence to local optima. The earliest genetic algorithms use only one mutation operator in producing the next generation. Each problem, even each stage of the genetic process in a single problem, may require appropriately different mutation operators for best results. Determining which mutation operators should be used is quite difficult and is usually learned through experience or by trial-and-error. This paper proposes a new genetic algorithm, the dynamic mutation genetic algorithm, to resolve these difficulties. The dynamic mutation genetic algorithm simultaneously uses several mutation operators in producing the next generation. The mutation ratio of each operator changes according to evaluation results from the respective offspring it produces. Thus, the appropriate mutation operators can be expected to have increasingly greater effects on the genetic process. Experiments are reported that show the proposed algorithm performs better than most genetic algorithms with single mutation operators.},
author = {Hong, Tzung Pei and Wang, Hong Shung and Chen, Wei Chou},
doi = {10.1023/A:1009642825198},
file = {::;:C\:/Users/carol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hong, Wang, Chen - 2000 - Simultaneously Applying Multiple Mutation Operators in Genetic Algorithms.pdf:pdf},
issn = {1572-9397},
journal = {Journal of Heuristics 2000 6:4},
keywords = {Artificial Intelligence,Calculus of Variations and Optimal Control,Management Science,Operations Research,Operations Research/Decision Theory,Optimization},
month = {sep},
number = {4},
pages = {439--455},
publisher = {Springer},
title = {{Simultaneously Applying Multiple Mutation Operators in Genetic Algorithms}},
url = {https://link.springer.com/article/10.1023/A:1009642825198},
volume = {6},
year = {2000}
}
@article{Zhang2008,
abstract = {This paper studies evolutionary programming and adopts reinforcement learning theory to learn individual mutation operators. A novel algorithm named RLEP (Evolutionary Programming based on Reinforcement Learning) is proposed. In this algorithm, each individual learns its optimal mutation operator based on the immediate and delayed performance of mutation operators. Mutation operator selection is mapped into a reinforcement learning problem. Reinforcement learning methods are used to learn optimal policies by maximizing the accumulated rewards. According to the calculated Q function value of each candidate mutation operator, an optimal mutation operator can be selected to maximize the learned Q function value. Four different mutation operators have been employed as the basic candidate operators in RLEP and one is selected for each individual in different generations. Our simulation shows the performance of RLEP is the same as or better than the best of the four basic mutation operators. {\textcopyright} 2007 Elsevier Inc. All rights reserved.},
author = {Zhang, Huaxiang and Lu, Jing},
doi = {10.1016/J.INS.2007.09.026},
file = {:C\:/Users/carol/Downloads/Adaptive evolutionary programming based on reinforcement learning.pdf:pdf},
issn = {0020-0255},
journal = {Information Sciences},
keywords = {Evolutionary programming,Mutation,Q value,Reinforcement learning},
month = {feb},
number = {4},
pages = {971--984},
publisher = {Elsevier},
title = {{Adaptive evolutionary programming based on reinforcement learning}},
volume = {178},
year = {2008}
}
@article{Friedrich2018,
abstract = {In many evolutionary algorithms (EAs), a parameter that needs to be tuned is that of the mutation rate, which determines the probability for each decision variable to be mutated. Typically, this rate is set to 1/n for the duration of the optimization, where n is the number of decision variables. This setting has the appeal that the expected number of mutated variables per iteration is one. In a recent theoretical study, it was proposed to sample the number of mutated variables from a power-law distribution. This results in a significantly higher probability on larger numbers of mutations, so that escaping local optima becomes more probable. In this paper, we propose another class of non-uniform mutation rates. We study the benefits of this operator in terms of average-case black-box complexity analysis and experimental comparison. We consider both pseudo-Boolean artificial landscapes and combinatorial problems (the Minimum Vertex Cover and the Maximum Cut). We observe that our non-uniform mutation rates significantly outperform the standard choices, when dealing with landscapes that exhibit large deceptive basins of attraction.},
author = {Friedrich, Tobias and Quinzan, Francesco and Wagner, Markus},
doi = {10.1145/3205455.3205515},
file = {:C\:/Users/carol/Downloads/Escaping large deceptive basins of attraction with heavy-tailed mutation operators.pdf:pdf},
isbn = {9781450356183},
journal = {GECCO 2018 - Proceedings of the 2018 Genetic and Evolutionary Computation Conference},
keywords = {Combinatorial optimization,Heavy-tailed mutation,Single-objective optimization},
month = {jul},
pages = {293--300},
publisher = {Association for Computing Machinery, Inc},
title = {{Escaping large deceptive basins of attraction with heavy-tailed mutation operators}},
year = {2018}
}
@article{Le2016,
abstract = {Effective automated program repair techniques have great potential to reduce the costs of debugging and maintenance. Previously proposed automated program repair (APR) techniques often follow a generate-and-validate and test-case-driven procedure: They first randomly generate a large pool of fix candidates and then exhaustively validate the quality of the candidates by testing them against existing or provided test suites. Unfortunately, many real-world bugs cannot be repaired by existing techniques even after more than 12 hours of computation in a multi-core cloud environment. More work is needed to advance the capabilities of modern APR techniques. We propose a new technique that utilizes the wealth of bug fixes across projects in their development history to effectively guide and drive a program repair process. Our main insight is that recurring bug fixes are common in real-world applications, and that previously-appearing fix patterns can provide useful guidance to an automated repair technique. Based on this insight, our technique first automatically mines bug fix patterns from the history of many projects. We then employ existing mutation operators to generate fix candidates for a given buggy program. Candidates that match frequently occurring historical bug fixes are considered more likely to be relevant, and we thus give them priority in the random search process. Finally, candidates that pass all the previously failed test cases are recommended as likely fixes. We compare our technique against existing generate-and-validate and test-driven APR approaches using 90 bugs from 5 Java programs. The experiment results show that our technique can produce good-quality fixes for many more bugs as compared to the baselines, while being reasonably computationally efficient: it takes less than 20 minutes, on average, to correctly fix a bug.},
author = {Le, Xuan Bach D. and Lo, David and {Le Goues}, Claire},
doi = {10.1109/SANER.2016.76},
file = {:C\:/Users/carol/Downloads/History_Driven_Program_Repair.pdf:pdf},
isbn = {9781509018550},
journal = {2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering, SANER 2016},
keywords = {Automated program repair,Graph mining,Mutation testing},
month = {may},
pages = {213--224},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{History driven program repair}},
volume = {1},
year = {2016}
}
@article{Wen2018,
abstract = {The effectiveness of search-based automated program repair is limited in the number of correct patches that can be successfully generated. There are two causes of such limitation. First, the search space does not contain the correct patch. Second, the search space is huge and therefore the correct patch cannot be generated (i.e., correct patches are either generated after incorrect plausible ones or not generated within the time budget). To increase the likelihood of including the correct patches in the search space, we propose to work at a fine granularity in terms of AST nodes. This, however, will further enlarge the search space, increasing the challenge to find the correct patches. We address the challenge by devising a strategy to prioritize the candidate patches based on their likelihood of being correct. Specifically, we study the use of AST nodes' context information to estimate the likelihood. In this paper, we propose CapGen, a context-aware patch generation technique. The novelty which allows CapGen to produce more correct patches lies in three aspects: (1) The fine-granularity design enables it to find more correct fixing ingredients; (2) The context-aware prioritization of mutation operators enables it to constrain the search space; (3) Three context-aware models enable it to rank correct patches at high positions before incorrect plausible ones. We evaluate CapGen on Defects4J and compare it with the state-of-the-art program repair techniques. Our evaluation shows that CapGen outperforms and complements existing techniques. CapGen achieves a high precision of 84.00% and can prioritize the correct patches before 98.78% of the incorrect plausible ones.},
author = {Wen, Ming and Chen, Junjie and Wu, Rongxin and Hao, Dan and Cheung, Shing Chi},
doi = {10.1145/3180155.3180233},
file = {:C\:/Users/carol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wen et al. - 2018 - Context-aware patch generation for better automated program repair.pdf:pdf},
isbn = {9781450356381},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering},
keywords = {Automated Program Repair,Context-Aware,Patch Prioritization},
pages = {1--11},
publisher = {IEEE Computer Society},
title = {{Context-aware patch generation for better automated program repair}},
url = {https://doi.org/10.1145/3180155.3180233},
volume = {2018-Janua},
year = {2018}
}
@article{Just2017,
abstract = {Existing mutation techniques produce vast numbers of equivalent, trivial, and redundant mutants. Selective mutation strategies aim to reduce the inherent redundancy of full mutation analysis to obtain most of its beneet for a fraction of the cost. Unfortunately, recent research has shown that there is no oxed selective mutation strategy that is eeective across a broad range of programs; the utility (i.e., usefulness) of a mutant produced by a given mutation operator varies greatly across programs. This paper hypothesizes that mutant utility, in terms of equivalence , triviality, and dominance, can be predicted by incorporating context information from the program in which the mutant is embedded. Speciically, this paper (1) explains the intuition behind this hypothesis with a motivational example, (2) proposes an approach for modeling program context using a program's abstract syntax tree, and (3) proposes and evaluates a series of program-context models for predicting mutant utility. The results for 129 mutation operators show that program context information greatly increases the ability to predict mutant utility. The results further show that it is important to consider program context for individual mutation operators rather than mutation operator groups. CCS CONCEPTS •Software and its engineering →Software testing and debug-ging;},
address = {New York, NY, USA},
author = {Just, Ren{\'{e}} and Kurtz, Bob and Ammann, Paul},
doi = {10.1145/3092703},
file = {:C\:/Users/carol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Just, Kurtz, Ammann - 2017 - Inferring Mutant Utility from Program Context.pdf:pdf},
isbn = {9781450350761},
journal = {Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis},
keywords = {- Software and its engineering  -> Software testin},
publisher = {ACM},
title = {{Inferring Mutant Utility from Program Context}},
year = {2017}
}
@article{Sharma2019,
abstract = {Adaptive Operator Selection (AOS) is an approach that controls discrete parameters of an Evolutionary Algorithm (EA) during the run. In this paper, we propose an AOS method based on Double Deep Q-Learning (DDQN), a Deep Reinforcement Learning method, to control the mutation strategies of Differential Evolution (DE). The application of DDQN to DE requires two phases. First, a neural network is trained offline by collecting data about the DE state and the benefit (reward) of applying each mutation strategy during multiple runs of DE tackling benchmark functions. We define the DE state as the combination of 99 different features and we analyze three alternative reward functions. Second, when DDQN is applied as a parameter controller within DE to a different test set of benchmark functions, DDQN uses the trained neural network to predict which mutation strategy should be applied to each parent at each generation according to the DE state. Benchmark functions for training and testing are taken from the CEC2005 benchmark with dimensions 10 and 30. We compare the results of the proposed DE-DDQN algorithm to several baseline DE algorithms using no online selection, random selection and other AOS methods, and also to the two winners of the CEC2005 competition. The results show that DE-DDQN outperforms the non-adaptive methods for all functions in the test set; while its results are comparable with the last two algorithms.},
archivePrefix = {arXiv},
arxivId = {1905.08006},
author = {Sharma, Mudita and L{\'{o}}pez-Ib{\'{a}}{\~{n}}ez, Manuel and Komninos, Alexandros and Kazakov, Dimitar},
doi = {10.1145/3321707.3321813},
eprint = {1905.08006},
file = {:C\:/Users/carol/Downloads/Deep reinforcement learning based parameter control in differential evolution.pdf:pdf},
isbn = {9781450361118},
journal = {GECCO 2019 - Proceedings of the 2019 Genetic and Evolutionary Computation Conference},
keywords = {Differential Evolution,Parameter Control,Reinforcement Learning},
month = {jul},
pages = {709--717},
publisher = {Association for Computing Machinery, Inc},
title = {{Deep reinforcement learning based parameter control in differential evolution}},
year = {2019}
}
@article{Glickman2000,
author = {Glickman, Matthew R. and Glickman, Matthew R. and Sycara, Katia},
file = {:C\:/Users/carol/Downloads/Reasons_for_premature_convergence_of_self-adapting_mutation_rates.pdf:pdf},
journal = {IN PROC. OF THE 2000 CONGRESS ON EVOLUTIONARY COMPUTATION},
pages = {62----69},
title = {{Reasons for Premature Convergence of Self-Adapting Mutation Rates}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.27.3062},
year = {2000}
}
@article{Soto2018,
abstract = {Automatic Software Repair (APR) has significant potential to reduce software maintenance costs by reducing the human effort required to localize and fix bugs. State-of-the-art generate-and-validate APR techniques select between and instantiate various mutation operators to construct candidate patches, informed largely by heuristic probability distributions. This may reduce effectiveness in terms of both efficiency and output quality. In practice, human developers have many options in terms of how to edit code to fix bugs, some of which are far more common than others (e.g., deleting a line of code is more common than adding a new class). We mined the most recent 100 bug-fixing commits from each of the 500 most popular Java projects in GitHub (the largest dataset to date) to create a probabilistic model describing edit distributions. We categorize, compare and evaluate the different mutation operators used in state-of-the-art approaches. We find that a probabilistic modelbased APR approach patches bugs more quickly in the majority of bugs studied, and that the resulting patches are of higher quality than those produced by previous approaches. Finally, we mine association rules for multi-edit source code changes, an understudied but important problem. We validate the association rules by analyzing how much of our corpus can be built from them. Our evaluation indicates that 84.6% of the multi-edit patches from the corpus can be built from the association rules, while maintaining 90% confidence.},
author = {Soto, Mauricio and {Le Goues}, Claire},
doi = {10.1109/SANER.2018.8330211},
file = {:C\:/Users/carol/Downloads/Using_a_probabilistic_model_to_predict_bug_fixes.pdf:pdf},
isbn = {9781538649695},
journal = {25th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2018 - Proceedings},
month = {apr},
pages = {221--231},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Using a probabilistic model to predict bug fixes}},
volume = {2018-March},
year = {2018}
}
@article{Serpell2010,
abstract = {The choice of mutation rate is a vital factor in the success of any genetic algorithm (GA), and for permutation representations this is compounded by the availability of several alternative mutation operators. It is now well understood that there is no one "optimal choice"; rather, the situation changes per problem instance and during evolution. This paper examines whether this choice can be left to the processes of evolution via selfadaptation, thus removing this nontrivial task fromtheGAuser and reducing the risk of poor performance arising from (inadvertent) inappropriate decisions. Self-adaptation has been proven successful for mutation step sizes in the continuous domain, and for the probability of applying bitwise mutation to binary encodings; here we examine whether this can translate to the choice and parameterisation of mutation operators for permutation encodings. We examine one method for adapting the choice of operator during runtime, and several different methods for adapting the rate at which the chosen operator is applied. In order to evaluate these algorithms, we have used a range of benchmark TSP problems. Of course this paper is not intended to present a state of the art in TSP solvers; rather, we use this well known problem as typical of many that require a permutation encoding, where our results indicate that self-adaptation can prove beneficial. The results show that GAs using appropriate methods to self-adapt their mutation operator and mutation rate find solutions of comparable or lower cost than algorithms with "static" operators, even when the latter have been extensively pretuned. Although the adaptive GAs tend to need longer to run, we show that is a price well worth paying as the time spent finding the optimal mutation operator and rate for the nonadaptive versions can be considerable. Finally, we evaluate the sensitivity of the self-adaptive methods to changes in the implementation, and to the choice of other genetic operators and population models. The results show that the methods presented are robust, in the sense that the performance benefits can be obtained in a wide range of host algorithms. {\textcopyright} 2010 by the Massachusetts Institute of Technology.},
author = {Serpell, Martin and Smith, James E.},
doi = {10.1162/EVCO_A_00006},
file = {:C\:/Users/carol/Downloads/Self-Adaptation of Mutation Operator and.pdf:pdf},
issn = {10636560},
journal = {Evolutionary Computation},
keywords = {Genetic algorithms,Mutation,Permutation encodings,Self-adaptation},
number = {3},
pages = {491--514},
pmid = {20560757},
title = {{Self-adaptation of mutation operator and probability for permutation representations in genetic algorithms}},
volume = {18},
year = {2010}
}
@article{TanvirAlamAnik2013,
abstract = {In order to achieve a satisfactory optimization performance by evolutionary programming (EP), it is necessary to ensure proper balance between exploration and exploitation. It is obvious that one single mutation operator is not the answer. Moreover, early loss of genetic diversity causes premature trapping around locally optimal points of the fitness landscape. This paper presents a fitness tracking based evolutionary programming (FTEP) algorithm incorporating a fitness tracking scheme to find the locally trapped individuals and treat them in a different way so that they are able to improve their performance. FTEP also incorporates several mutation operators in one algorithm and employs a self-adaptive strategy to gradually self-adapt the mutation operators in order to apply an appropriate mutation operator on the individual based on its need. A test-suite of 25 functions has been used to evaluate the performance of FTEP.},
author = {{Tanvir Alam Anik}, Md and Ahmed, Saif and {Monirul Islam}, Md},
doi = {10.1145/2464576.2464609},
file = {:C\:/Users/carol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tanvir Alam Anik, Ahmed, Monirul Islam - 2013 - Fitness tracking based evolutionary programming A novel approach for function optimizati.pdf:pdf},
isbn = {9781450319645},
journal = {GECCO 2013 - Proceedings of the 2013 Genetic and Evolutionary Computation Conference Companion},
keywords = {Evolutionary programming,Fitness tracking,Mutation,Stagnant population,fitness tracking,mutation,stagnant population},
pages = {57--58},
title = {{Fitness tracking based evolutionary programming: A novel approach for function optimization}},
url = {http://www.ntu.edu.sg/home/EPNSugan},
year = {2013}
}
@article{Fialho2009,
abstract = {The performance of many efficient algorithms critically depends on the tuning of their parameters, which on turn depends on the problem at hand. For example, the performance of Evolutionary Algorithms critically depends on the judicious setting of the operator rates....},
author = {Fialho, {\'{A}}lvaro and {Da Costa}, Luis and Schoenauer, Marc and Sebag, Mich{\`{e}}le},
doi = {10.1007/978-3-642-11169-3_13},
file = {:C\:/Users/carol/Downloads/aosLION.pdf:pdf},
isbn = {3642111688},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {176--190},
publisher = {Springer, Berlin, Heidelberg},
title = {{Dynamic Multi-Armed Bandits and Extreme Value-Based Rewards for Adaptive Operator Selection in Evolutionary Algorithms}},
url = {https://link.springer.com/chapter/10.1007/978-3-642-11169-3_13},
volume = {5851 LNCS},
year = {2009}
}
@article{Lee1999,
abstract = {In this paper, we propose a new type of evolution strategies combined with reinforcement learning. We use the change of fitness occurred by mutation to make the reinforcement signals which estimate and control the step length of mutation. With this proposed method, the convergence rate is improved. Also, we use Cauchy distributed mutation to increase global convergence faculty. Cauchy distributed mutation is more likely to escape from a local minimum or move away from a plateau than Gaussian distributed mutation. After an outline of the history of evolution strategies, we will explain the evolution strategies combined with the reinforcement learning, that is reinforcement evolution strategies. The performance of proposed method will be estimated by comparison with conventional evolution strategies on several test problems.},
author = {Lee, Sang Hwan and Jun, Hyo Byung and Sim, Kwee Bo},
doi = {10.1109/FUZZY.1999.793017},
file = {:C\:/Users/carol/Downloads/Performance_improvement_of_evolution_strategies_using_reinforcement_learning.pdf:pdf},
journal = {IEEE International Conference on Fuzzy Systems},
publisher = {IEEE},
title = {{Performance improvement of evolution strategies using reinforcement learning}},
volume = {2},
year = {1999}
}
@article{Murata1996,
abstract = {When a genetic algorithm is applied to sequencing problems, various crossover and mutation operators are applicable. Because the performance of genetic algorithms depends on the choice of such operators, we have to carefully select appropriate operators for constructing high performance genetic algorithms. Moreover the performance also depends on the specifications of the crossover and mutation probabilities. In this paper, we discuss the selection of genetic operators and their probability specifications for sequencing problems. First we examine the performance of various crossover and mutation operators by computer simulations on flowshop scheduling problems. Then we point out that the combination of high performance crossover and mutation operators does not always lead to a high performance genetic algorithm because of the negative combination effect of those two operators. Finally we explain how a high performance genetic algorithm can be constructed by utilizing the positive combination effect of crossover and mutation.},
author = {Murata, Tadahiko and Ishibuchi, Hisao},
doi = {10.1109/ICEC.1996.542355},
file = {:C\:/Users/carol/Downloads/Positive_and_negative_combination_effects_of_crossover_and_mutation_operators_in_sequencing_problems.pdf:pdf},
journal = {Proceedings of the IEEE Conference on Evolutionary Computation},
pages = {170--175},
publisher = {IEEE},
title = {{Positive and negative combination effects of crossover and mutation operators in sequencing problems}},
year = {1996}
}
@article{Hong2002,
abstract = {Traditional genetic algorithms use only one crossover and one mutation operator to generate the next generation. The chosen crossover and mutation operators are critical to the success of genetic algorithms. Different crossover or mutation operators, however, are suitable for different problems, even for different stages of the genetic process in a problem. Determining which crossover and mutation operators should be used is quite difficult and is usually done by trial-and-error. In this paper, a new genetic algorithm, the dynamic genetic algorithm (DGA), is proposed to solve the problem. The dynamic genetic algorithm simultaneously uses more than one crossover and mutation operators to generate the next generation. The crossover and mutation ratios change along with the evaluation results of the respective offspring in the next generation. By this way, we expect that the really good operators will have an increasing effect in the genetic process. Experiments are also made, with results showing the proposed algorithm performs better than the algorithms with a single crossover and a single mutation operator.},
author = {Hong, Tzung Pei and Wang, Hong Shung and Lin, Wen Yang and Lee, Wen Yuan},
doi = {10.1023/A:1012815625611},
file = {:C\:/Users/carol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hong et al. - 2002 - Evolution of Appropriate Crossover and Mutation Operators in a Genetic Process.pdf:pdf},
issn = {1573-7497},
journal = {Applied Intelligence 2002 16:1},
keywords = {Artificial Intelligence,Machines,Manufacturing,Mechanical Engineering,Processes,Tools},
month = {jan},
number = {1},
pages = {7--17},
publisher = {Springer},
title = {{Evolution of Appropriate Crossover and Mutation Operators in a Genetic Process}},
url = {https://link.springer.com/article/10.1023/A:1012815625611},
volume = {16},
year = {2002}
}
@article{Smigielska2021,
abstract = {Genetic improvement (GI) tools find improved program versions by modifying the initial program. These can be used for the purpose of automated program repair (APR). GI uses software transformations, called mutation operators, such as deletions, insertions, and replacements of code fragments. Current edit selection strategies, however, under-explore the search spaces of insertion and replacement operators. Therefore, we implement a uniform strategy based on the relative operator search space sizes. We evaluate it on the QuixBugs repair benchmark and find that the uniform strategy has the potential for improving APR tool performance. We also analyse the efficacy of the different mutation operators with regard to the type of code fragment they are applied to. We find that, for all operators, choosing expression statements as target statements is the most successful for finding program variants with improved or preserved fitness (50.03%, 33.12% and 23.85% for deletions, insertions and replacements, respectively), whereas choosing declaration statements is the least effective (3.16%, 10.82% and 3.14% for deletions, insertions and replacements).},
author = {Smigielska, Marta and Blot, Aymeric and Petke, Justyna},
doi = {10.1109/GI52543.2021.00009},
file = {:C\:/Users/carol/Downloads/Uniform_Edit_Selection_for_Genetic_Improvement_Empirical_Analysis_of_Mutation_Operator_Efficacy (1).pdf:pdf},
isbn = {9781665444668},
journal = {Proceedings - 2021 IEEE/ACM International Workshop on Genetic Improvement, GI 2021},
keywords = {genetic improvement,mutation operators},
month = {may},
pages = {1--8},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Uniform Edit Selection for Genetic Improvement: Empirical Analysis of Mutation Operator Efficacy}},
year = {2021}
}
@article{Anik2013,
abstract = {A proper balance between exploration and exploitation is essential to maintain adequate genetic diversity within the evolving population of an evolutionary algorithm (EA). Early loss of genetic diversity causes premature trapping around the locally optimal points of the fitness landscape. Evolutionary programming (EP), one of the major branches of EA, obtains exploration and exploitation abilities by mutation operators. As one single mutation operator is not sufficient, mixing several explorative and exploitative mutation operators can improve the performance of EP. This paper presents a mixed mutation scheme for EP based on a guided selection strategy. This strategy guides the participation of mutation operators throughout the evolutionary process. The proposed algorithm has been examined on a test-suite of 20 benchmark functions. Experimental results show that combining different mutation operators along with the guided selection strategy significantly enhance the performance of EP. {\textcopyright} 2013 IEEE.},
author = {Anik, Md Tanvir Alam and Ahmed, Saif},
doi = {10.1109/ICIEV.2013.6572647},
file = {:C\:/Users/carol/Downloads/A_mixed_mutation_approach_for_evolutionary_programming_based_on_guided_selection_strategy.pdf:pdf},
isbn = {9781479903979},
journal = {2013 International Conference on Informatics, Electronics and Vision, ICIEV 2013},
keywords = {evolutionary programming,exploitation,exploration,guided selection,mutation pool},
title = {{A mixed mutation approach for evolutionary programming based on guided selection strategy}},
year = {2013}
}
@article{Yaman2010,
author = {Yaman, Fatih and Yilmaz, Asim Egemen},
doi = {10.1109/SIU.2010.5653114},
file = {:C\:/Users/carol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yaman, Yilmaz - 2010 - Investigation of fixed and variable mutation rate performances in real coded Genetic Algorithm for uniform circul.pdf:pdf},
isbn = {9781424496716},
journal = {SIU 2010 - IEEE 18th Signal Processing and Communications Applications Conference},
pages = {594--597},
title = {{Investigation of fixed and variable mutation rate performances in real coded Genetic Algorithm for uniform circular antenna array pattern synthesis problem}},
year = {2010}
}
@article{Hong2014,
abstract = {The mutation operator is the only genetic operator in Evolutionary Programming (EP). In the past researchers have nominated Gaussian, Cauchy, and L{\'{e}}vy distributions as mutation operators. According to the No Free Lunch theorem [9], no single mutation operator is able to outperform all others over the set of all possible functions. Potentially there is a lot of useful information generated when EP is ongoing. In this paper, we collect such information and propose a step size based self-adaptive mutation operator for Evolutionary Programming (SSEP). In SSEP, the mutation operator might be changed during the evolutionary process, based on the step size, from generation to generation. Principles for selecting an appropriate mutation operator for EP is proposed, with SSEP grounded on the principles. SSEP is shown to outperform static mutation operators in Evolutionary Programming on most of the functions tested. We also compare the experimental results of SSEP with other recent Evolutionary Programming methods, which uses multiple mutation operators.},
author = {Hong, Libin and Drake, John H. and {\"{O}}zcan, Ender},
doi = {10.1145/2598394.2609873},
file = {:C\:/Users/carol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hong, Drake, {\"{O}}zcan - 2014 - A step size based self-adaptive mutation operator for Evolutionary Programming.pdf:pdf},
isbn = {9781450328814},
journal = {GECCO 2014 - Companion Publication of the 2014 Genetic and Evolutionary Computation Conference},
keywords = {Convergence,Evolutionary Programming,Function optimization,Mutation operator,Self-adaptive,Step size},
pages = {1381--1387},
publisher = {Association for Computing Machinery},
title = {{A step size based self-adaptive mutation operator for Evolutionary Programming}},
url = {http://dx.doi.org/10.1145/2598394.2609873.},
year = {2014}
}
@article{Julstrom1997,
abstract = {The probabilities with which a genetic algorithm applies its operators have sometimes been set adaptively; information derived from the algorithm's performance has been used to revise the probabilities as the GA runs. This paper reviews one such mechanism, which assigns probabilities to crossover and mutation, and extends it to assign probabilities to three or more operators. The extension guarantees that no operator will be excluded, even if it has recently been ineffective. Several versions of the extended mechanism are tested in a steady-state GA for the rectilinear Steiner problem, in which we seek a tree of minimum length, made up of horizontal and vertical line segments, that connects a set of given points. The coding chosen for the trees gives rise to three genetic operators, a crossover and two mutations. The operator probabilities develop in interesting ways, but the algorithm itself never identifies trees shorter than those found by the same GA with fixed operator probabilities. This raises questions about how information available to a GA as it runs can be used. {\textcopyright} 1997 ACM.},
author = {Julstrom, Bryant A.},
doi = {10.1145/331697.331746},
file = {:C\:/Users/carol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Julstrom - 1997 - Adaptive operator probabilities in a genetic algorithm that applies three operators.pdf:pdf},
isbn = {0897918509},
journal = {Proceedings of the ACM Symposium on Applied Computing},
keywords = {Adaptive operator probabilities,More than two operators,Rectilinear steiner problem},
pages = {233--238},
publisher = {Association for Computing Machinery},
title = {{Adaptive operator probabilities in a genetic algorithm that applies three operators}},
year = {1997}
}
@article{Jackson2011,
abstract = {In various evolutionary computing algorithms, mutation operators are employed as a means of preserving diversity of populations. In genetic programming (GP), by contrast, mutation tends to be viewed as offering little benefit, to the extent that it is often not implemented in GP systems. We investigate the role of mutation in GP, and attempt to answer questions regarding its effectiveness as a means for enhancing diversity, and the consequent effects of any such diversity promotion on the solution finding performance of the algorithm. We find that mutation can be beneficial for GP, but subject to the proviso that it be tailored to enhance particular forms of diversity.},
address = {New York, New York, USA},
author = {Jackson, David},
doi = {10.1145/2001576},
file = {:C\:/Users/carol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jackson - 2011 - Mutation as a Diversity Enhancing Mechanism in Genetic Programming.pdf:pdf},
isbn = {9781450305570},
journal = {Proceedings of the 13th annual conference on Genetic and evolutionary computation - GECCO '11},
keywords = {D12 [Programming Techniques]: Automatic Programmin,I22 [Artificial Intelligence] Automatic Programmin,I26 [Artificial Intelligence] Learning-induction G},
publisher = {ACM Press},
title = {{Mutation as a Diversity Enhancing Mechanism in Genetic Programming}},
year = {2011}
}
@article{Thierens2005,
abstract = {Learning the optimal probabilities of applying an exploration operator from a set of alternatives can be done by self-adaptation or by adaptive allocation rules. In this paper we consider the latter option. The allocation strategies discussed in the literature basically belong to the class of probability matching algorithms. These strategies adapt the operator probabilities in such a way that they match the reward distribution. In this paper we introduce an alternative adaptive allocation strategy, called the adaptive pursuit method. We compare this method with the probability matching approach in a non-stationary environment. Calculations and experimental results show the superior performance of the adaptive pursuit algorithm. If the reward distributions stay stationary for some time, the adaptive pursuit method converges rapidly and accurately to an operator probability distribution that results in a much higher probability of selecting the current optimal operator and a much higher average reward than with the probability matching strategy. Yet most importantly, the adaptive pursuit scheme remains sensitive to changes in the reward distributions, and reacts swiftly to non-stationary shifts in the environment. Copyright 2005 ACM.},
author = {Thierens, Dirk},
doi = {10.1145/1068009.1068251},
file = {:C\:/Users/carol/Downloads/An adaptive pursuit strategy for allocating operator probabilities.pdf:pdf},
isbn = {1595930108},
journal = {GECCO 2005 - Genetic and Evolutionary Computation Conference},
keywords = {Adaptive operator allocation,Adaptive pursuit,Multi-armed bandit,Non-stationary environment,Non-stationary operator probabilities},
pages = {1539--1546},
title = {{An adaptive pursuit strategy for allocating operator probabilities}},
year = {2005}
}
@article{Ali2013,
abstract = {The conventional Genetic algorithms (GAs) use a single mutation operator for whole population, It means that all solutions in population apply same leaning strategy. This property may cause lack of intelligence for specific individual, which is difficult to deal with complex situation. Different mutation operators have been suggested in GAs, but it is difficult to select which mutation operator should be used in the evolutionary process of GAs. In this paper, the fast learning automata is applied in GAs to automatically choose the most optimal strategy while solving the problem. Experimental results on different benchmark problems determines that the proposed method obtains the fast convergence speed and improve the performance of GAs. {\textcopyright} 2013 IEEE.},
author = {Ali, Korejo Imtiaz and Brohi, Kamran},
doi = {10.1109/FIT.2013.18},
file = {:C\:/Users/carol/Downloads/An_Adaptive_Learning_Automata_for_Genetic_Operators_Allocation_Probabilities.pdf:pdf},
isbn = {9781479922932},
journal = {Proceedings - 11th International Conference on Frontiers of Information Technology, FIT 2013},
keywords = {Adaptive Genetic Operators,Genetic Algorithms (GAs),Learning Automata},
pages = {55--59},
title = {{An adaptive learning automata for genetic operators allocation probabilities}},
year = {2013}
}
@article{Soto2019,
abstract = {The error repair process in software systems is, historically, a resource-consuming task that relies heavily in developer manual effort. Automatic program repair approaches enable the repair of software with minimum human interaction, therefore, mitigating the burden from developers. However, a problem automatically generated patches commonly suffer is generating low-quality patches (which overfit to one program specification, thus not generalizing to an independent oracle evaluation). This work proposes a set of mechanisms to increase the quality of plausible patches including an analysis of test suite behavior and their key characteristics for automatic program repair, analyzing developer behavior to inform the mutation operator selection distribution, and a study of patch diversity as a means to create consolidated higher quality fixes.},
author = {Soto, Mauricio},
doi = {10.1109/ASE.2019.00147},
file = {:C\:/Users/carol/Downloads/Improving_Patch_Quality_by_Enhancing_Key_Components_of_Automatic_Program_Repair.pdf:pdf},
isbn = {9781728125084},
journal = {Proceedings - 2019 34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019},
keywords = {Automatic Program Repair,Patch Quality},
month = {nov},
pages = {1230--1233},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Improving patch quality by enhancing key components of automatic program repair}},
year = {2019}
}
@article{Maturana2009,
abstract = {The goal of Adaptive Operator Selection is the on-line control of the choice of variation operators within Evolutionary Algorithms. The control process is based on two main components, the credit assignment, that defines the reward that will be used to evaluate the quality of an operator after it has been applied, and the operator selection mechanism, that selects one operator based on some operators qualities. Two previously developed Adaptive Operator Selection methods are combined here: Compass evaluates the performance of operators by considering not only the fitness improvements from parent to offspring, but also the way they modify the diversity of the population, and their execution time; Dynamic Multi-Armed Bandit proposes a selection strategy based on the well-known UCB algorithm, achieving a compromise between exploitation and exploration, while nevertheless quickly adapting to changes. Tests with the proposed method, called ExCoDyMAB, are carried out using several hard instances of the Satisfiability problem (SAT). Results show the good synergetic effect ofcombining both approaches. {\textcopyright} 2009 IEEE.},
author = {Maturana, Jorge and Fialho, {\'{A}}lvaro and Saubion, Fr{\'{e}}d{\'{e}}ric and Schoenauer, Marc and Sebag, Miche'le},
doi = {10.1109/CEC.2009.4982970},
file = {:C\:/Users/carol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Maturana et al. - 2009 - Extreme compass and dynamic multi-armed bandits for adaptive operator selection.pdf:pdf},
isbn = {9781424429592},
journal = {2009 IEEE Congress on Evolutionary Computation, CEC 2009},
pages = {365--372},
publisher = {IEEE Computer Society},
title = {{Extreme compass and dynamic multi-armed bandits for adaptive operator selection}},
year = {2009}
}
@misc{Tuson1998,
author = {Tuson, A.},
file = {:C\:/Users/carol/Downloads/apating operator prob.pdf:pdf},
title = {{Adapting Operator Probabilities In Genetic Algorithms}},
url = {https://www.researchgate.net/publication/2863131_Adapting_Operator_Probabilities_In_Genetic_Algorithms},
urldate = {2022-06-04},
year = {1998}
}
@article{Fialho2010,
abstract = {Adaptive Operator Selection (AOS) turns the impacts of the applications of variation operators into Operator Selection through a Credit Assignment mechanism. However, most Credit Assignment schemes make direct use of the fitness gain between parent and offspring. A first issue is that the Operator Selection technique that uses such kind of Credit Assignment is likely to be highly dependent on the a priori unknown bounds of the fitness function. Additionally, these bounds are likely to change along evolution, as fitness gains tend to get smaller as convergence occurs. Furthermore, and maybe more importantly, a fitness-based credit assignment forbid any invariance by monotonous transformation of the fitness, what is a usual source of robustness for comparison-based Evolutionary Algorithms. In this context, this paper proposes two new Credit Assignment mechanisms, one inspired by the Area Under the Curve paradigm, and the other close to the Sum of Ranks. Using fitness improvement as raw reward, and directly coupled to a Multi-Armed Bandit Operator Selection Rule, the resulting AOS obtain very good performances on both the OneMax problem and some artificial scenarios, while demonstrating their robustness with respect to hyper-parameter and fitness transformations. Furthermore , using fitness ranks as raw reward results in a fully comparison-based AOS with reasonable performances.},
address = {New York, New York, USA},
author = {Fialho, {\'{A}}lvaro and Schoenauer, Marc and Sebag, Mich{\`{e}}le},
doi = {10.1145/1830483},
file = {:C\:/Users/carol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fialho, Schoenauer, Sebag - Unknown - Toward Comparison-based Adaptive Operator Selection.pdf:pdf},
isbn = {9781450300728},
journal = {Proceedings of the 12th annual conference on Genetic and evolutionary computation - GECCO '10},
keywords = {Adaptive Operator Selection,Control Methods,I28 [Computing Methodologies]: Artificial Intellig,Multi-Armed Bandits,ROC Area Under Curve,Ranks,and Search General Terms Algorithms Keywords Param},
publisher = {ACM Press},
title = {{Toward Comparison-based Adaptive Operator Selection}},
url = {http://coco.gforge.inria.fr/doku.php?id=},
year = {2010}
}
@article{Vafaee2008,
abstract = {We propose a new method of dynamically adapting the probabilities of genetic operators based on the global behavior of the population for each generation. The proposed method consists of two main components which are assigning credits to operators according to the fitness improvements of the individuals, and updating the operators' probabilities at the onset of each generation. Each of these components can be implemented based on various mathematical approaches; hitherto, two different variants have been investigated. To leverage our previous work we used Gene Expression Programming (GEP) as a benchmark to investigate the power of our novel approach. Nevertheless, this new method can be easily extended to other genetic programming variants. Our experimental results on two symbolic regression problems show that this method follows a faster convergence curve and it improves the performance considerably while imposing an insignificant additional cost. {\textcopyright} 2008 Springer-Verlag Berlin Heidelberg.},
author = {Vafaee, Fatemeh and Nelson, Peter C. and Zhou, Chi and Xiao, Weimin},
doi = {10.1007/978-3-540-78987-1_15},
file = {:C\:/Users/carol/Downloads/Dynamic_Adaptation_of_Genetic_Operators_Probabili.pdf:pdf},
isbn = {9783540789864},
issn = {1860949X},
journal = {Studies in Computational Intelligence},
pages = {159--168},
title = {{Dynamic adaptation of genetic operators' probabilities}},
volume = {129},
year = {2008}
}
@article{Aleti2016,
abstract = {Evolutionary algorithms (EAs) are robust stochastic optimisers that perform well over a wide range of problems. Their robustness, however, may be affected by several adjustable parameters, such as ...},
author = {Aleti, Aldeida and Moser, Irene},
doi = {10.1145/2996355},
file = {:C\:/Users/carol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Aleti, Moser - 2016 - A Systematic Literature Review of Adaptive Parameter Control Methods for Evolutionary Algorithms.pdf:pdf},
issn = {15577341},
journal = {ACM Computing Surveys (CSUR)},
keywords = {Evolutionary algorithms,adaptive parameter control},
month = {oct},
number = {3},
publisher = {
		ACM
		PUB27
		New York, NY, USA
	},
title = {{A Systematic Literature Review of Adaptive Parameter Control Methods for Evolutionary Algorithms}},
url = {https://dl.acm.org/doi/abs/10.1145/2996355},
volume = {49},
year = {2016}
}
@article{Hesser1991,
abstract = {In this paper the optimal parameter setting of Genetic Algorithms (GAs) is investigated. Particular attention has been paid to the dependence of the mutation probability P M upon two parameters, the dimension of the configuration space...},
author = {Hesser, J{\"{u}}rgen and M{\"{a}}inner, Reinhard},
doi = {10.1007/BFB0029727},
file = {:C\:/Users/carol/Downloads/Hesser-M{\"{a}}nner1991_Chapter_TowardsAnOptimalMutationProbab.pdf:pdf},
isbn = {9783540541486},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {23--32},
publisher = {Springer, Berlin, Heidelberg},
title = {{Towards an optimal mutation probability for genetic algorithms}},
url = {https://link.springer.com/chapter/10.1007/BFb0029727},
volume = {496 LNCS},
year = {1991}
}
@article{Vafaee2008a,
abstract = {This work is concerned with proposing an adaptive method to dynamically adjust genetic operator probabilities throughout the evolutionary process. The proposed method relies on the individual preferences of each chromosome, rather than the global behavior of the whole population. Hence, each individual carries its own set of parameters, including the probabilities of the genetic operators. The carried parameters undergo the same evolutionary process as the carriers-the chromosomes-do. We call this method Evolved Evolutionary Algorithm (E2A) as it has an additional evolutionary process to evolve control parameters. Furthermore, E2A employs a supplementary mutation operator (DE-mutation) which utilizes the previously overlooked numerical optimization model known as the Differential Evolution to expedite the optimization rate of the genetic parameters. To leverage our previous work, we used Gene Expression Programming (GEP) as a benchmark to determine the performance of our proposed method. Nevertheless, E2A can be easily extended to other genetic programming variants. As the experimental results on a wide array of regression problems demonstrate, the E2A method reveals a faster rate of convergence and provides fitter ultimate solutions. However, to further expose the power of the E2A method, we compared it to related methods using selfadaptation previously applied to Genetic Algorithms. Our benchmarking on the same set of regression problems proves the supremacy of our proposed method both in the accuracy and simplicity of the final solutions. {\textcopyright} 2008 IEEE.},
author = {Vafaee, Fatemeh and Xiao, Weimin and Nelson, Peter C. and Zhou, Chi},
doi = {10.1109/ICMLA.2008.45},
file = {:C\:/Users/carol/Downloads/Adaptively_Evolving_Probabilities_of_Genetic_Operators.pdf:pdf},
isbn = {9780769534954},
journal = {Proceedings - 7th International Conference on Machine Learning and Applications, ICMLA 2008},
pages = {292--299},
title = {{Adaptively evolving probabilities of genetic operators}},
year = {2008}
}
@misc{J.E.Pettinger2002,
author = {{J. E. Pettinger}, R. Everson},
file = {:C\:/Users/carol/Downloads/Controlling Genetic Algorithms with Reinforcement Learning.pdf:pdf},
title = {{Controlling Genetic Algorithms With Reinforcement Learning | Semantic Scholar}},
url = {https://www.semanticscholar.org/paper/Controlling-Genetic-Algorithms-With-Reinforcement-Pettinger-Everson/4ed93dab19e1d90df50dfcdc5fce12d581e86e94},
urldate = {2022-06-05},
year = {2002}
}
@article{Eiben2007,
abstract = {The research reported in this paper is concerned with assessing the usefulness of reinforcment learning (RL) for on-line calibration of parameters in evolutionary algorithms (EA). We are running an RL procedure and the EA simultaneously and the RL is changing the EA...},
author = {Eiben, A. E. and Horvath, Mark and Kowalczyk, Wojtek and Schut, Martijn C.},
doi = {10.1007/978-3-540-69868-5_10},
file = {:C\:/Users/carol/Downloads/Reinforcement_Learning_for_Online_Control_of_Evolu.pdf:pdf},
isbn = {3540698671},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {151--160},
publisher = {Springer, Berlin, Heidelberg},
title = {{Reinforcement Learning for Online Control of Evolutionary Algorithms}},
url = {https://link.springer.com/chapter/10.1007/978-3-540-69868-5_10},
volume = {4335 LNAI},
year = {2007}
}
@article{Fialho2008,
abstract = {Credit Assignment is an important ingredient of several proposals that have been made for Adaptive Operator Selection. Instead of the average fitness improvement of newborn offspring, this paper proposes to use some empirical order statistics of those improvements, arguing that rare but highly beneficial jumps matter as much or more than frequent but small improvements. An extreme value based Credit Assignment is thus proposed, rewarding each operator with the best fitness improvement observed in a sliding window for this operator. This mechanism, combined with existing Adaptive Operator Selection rules, is investigated in an EC-like setting. First results show that the proposed method allows both the Adaptive Pursuit and the Dynamic Multi-Armed Bandit selection rules to actually track the best operators along evolution. {\textcopyright} 2008 Springer-Verlag Berlin Heidelberg.},
author = {Fialho, {\'{A}}lvaro and {Da Costa}, Lu{\'{i}}s and Schoenauer, Marc and Sebag, Mich{\`{e}}le},
doi = {10.1007/978-3-540-87700-4_18},
file = {:C\:/Users/carol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fialho et al. - 2008 - Extreme value based adaptive operator selection.pdf:pdf},
isbn = {3540876995},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {175--184},
title = {{Extreme value based adaptive operator selection}},
volume = {5199 LNCS},
year = {2008}
}
@article{DaCosta2008,
author = {da Costa, Luis and Fialho, {\'{A}}lvaro and Schoenauer, Marc and Sebag, Mich{\`{e}}le},
doi = {10.1145/1389095.1389272ï},
file = {:C\:/Users/carol/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/da Costa et al. - 2008 - Adaptive Operator Selection with Dynamic Multi-Armed Bandits.pdf:pdf},
isbn = {9781605581316},
pages = {913--920},
publisher = {ACM},
title = {{Adaptive Operator Selection with Dynamic Multi-Armed Bandits}},
url = {https://hal.inria.fr/inria-00278542v1},
year = {2008}
}
@misc{A.Tuson1998,
author = {{A. Tuson}, P.Ross},
file = {:C\:/Users/carol/Downloads/Cost_Based_Operator_Rate_Adaptation_An_Investigati.pdf:pdf},
title = {{Cost Based Operator Rate Adaptation: An Investigation}},
url = {https://www.researchgate.net/publication/2237196_Cost_Based_Operator_Rate_Adaptation_An_Investigation},
urldate = {2022-06-04},
year = {1998}
}
@article{Yang2006,
abstract = {In this paper, a new gene based adaptive mutation scheme is proposed for genetic algorithms (GAs), where the information on gene based fitness statistics and on gene based allele distribution statistics are correlated to explicitly adapt the mutation probability for each gene locus over time. A convergence control mechanism is combined with the proposed mutation scheme to maintain sufficient diversity in the population. Experiments are carried out to compare the proposed mutation scheme to traditional mutation and two advanced adaptive mutation schemes on a set of optimization problems. The experimental results show that the proposed mutation scheme efficiently improves GA's performance. Copyright 2006 ACM.},
author = {Yang, Shengxiang and Uyar, Sima},
doi = {10.1145/1141277.1141499},
file = {:C\:/Users/carol/Downloads/Adaptive mutation with fitness and allele distribution correlation for genetic algorithms.pdf:pdf},
isbn = {1595931082},
journal = {Proceedings of the ACM Symposium on Applied Computing},
keywords = {Fitness and allele distribution correlation,Gene based adaptive mutation,Genetic algorithms},
pages = {940--944},
publisher = {Association for Computing Machinery},
title = {{Adaptive mutation with fitness and allele distribution correlation for genetic algorithms}},
volume = {2},
year = {2006}
}
@article{Vafaee2010,
abstract = {Exploration and exploitation are the two cornerstones which characterize Evolutionary Algorithms (EAs) capabilities. Maintaining the reciprocal balance of the explorative and exploitative power is the key to the success of EA applications. Accordingly, in this work the canonical Genetic Algorithm is augmented by a new mutation scheme that is capable of exploring the unseen regions of the search space, and simultaneously exploiting the already-found promising elements. The proposed mutation operator specifies different mutation rates for different sites (loci) of the individuals. These site-specific rates are wisely derived based on the fitness and structure of the population individuals. In order to retain the balance of the required exploration and exploitation, the mutation rates are adapted during the evolution. To demonstrate the efficacy of the proposed algorithm, the method is evaluated using a set of benchmark problems and the outcome is compared with a series of well-known relevant algorithms. The results demonstrate that the newly suggested method significantly outperforms its rivals. {\textcopyright} 2010 IEEE.},
author = {Vafaee, Fatemeh and Nelson, Peter C.},
doi = {10.1109/CEC.2010.5586142},
file = {:C\:/Users/carol/Downloads/An_explorative_and_exploitative_mutation_scheme.pdf:pdf},
isbn = {9781424469109},
journal = {2010 IEEE World Congress on Computational Intelligence, WCCI 2010 - 2010 IEEE Congress on Evolutionary Computation, CEC 2010},
title = {{An explorative and exploitative mutation scheme}},
year = {2010}
}
@article{Stanczak1999,
abstract = {In this paper we propose a new method of tuning the probabilities of the genetic operators. We assume that every member of the optimized population conducts his own ranking of genetic operator qualities. This ranking becomes a base to compute the probabilities of appearance and execution of genetic operators. This set of probabilities is a base of experience of every individual and according to this it chooses the operator in every iteration of the algorithm. Due to this experience one can maximize the chance of offspring survival.},
author = {Stanczak, Jaroslaw T. and Mulawka, Jan J. and Verma, Brijesh K.},
doi = {10.1109/ICCIMA.1999.798575},
file = {:C\:/Users/carol/Downloads/Genetic_algorithms_with_adaptive_probabilities_of_operator_selection.pdf:pdf},
isbn = {0769503004},
journal = {Proceedings - 3rd International Conference on Computational Intelligence and Multimedia Applications, ICCIMA 1999},
pages = {464--468},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Genetic algorithms with adaptive probabilities of operator selection}},
year = {1999}
}
@article{Srinivas1994,
abstract = {In this paper we describe an efficient approach for multimodal function optimization using Genetic Algorithms (GAs). We recommend the use of adaptive probabilities of crossover and mutation to realize the twin goals of maintaining diversity in the population and sustaining the convergence capacity of the GA. In the Adaptive Genetic Algorithm (AGA), the probabilities of crossover and mutation, pc and pm, are varied depending on the fitness values of the solutions. High-fitness solutions are ‘protected', while solutions with subaverage fitnesses are totally disrupted. By using adaptively varying Pc and Pm, we also provide a solution to the problem of deciding the optimal values of pc and Pm, i.e., pc and pm need not be specified at all. The AGA is compared with previous approaches for adapting operator probabilities in genetic algorithms. The schema theorem is derived for the AGA, and the working of the AGA is analyzed. We compare the performance of the AGA with that of the Standard GA (SGA) in optimizing several nontrivial multimodal functions with varying degrees of complexity. For most functions, the AGA converges to the global optimum in far fewer generations than the SGA, and it gets stuck at a local optimum fewer times. Our experiments demonstrate that the relative performance of the AGA as compared to that of the SGA improves as the epistacity and the multimodal nature of the objective function increase. We believe that the AGA is the first step in realizing a class of self organizing GAs capable of adapting themselves in locating the global optimum in a multimodal landscape. {\textcopyright} 1994 IEEE},
author = {Srinivas, M. and Patnaik, L. M.},
doi = {10.1109/21.286385},
file = {:C\:/Users/carol/Downloads/Adaptive_probabilities_of_crossover_and_mutation_in_genetic_algorithms.pdf:pdf},
issn = {21682909},
journal = {IEEE Transactions on Systems, Man and Cybernetics},
number = {4},
pages = {656--667},
title = {{Adaptive Probabilities of Crossover and Mutation in Genetic Algorithms}},
volume = {24},
year = {1994}
}
